---
title: "Milestone 6"
author: "Diego Martinez"
date: "4/3/2020"
output: bookdown::pdf_document2
bibliography: [bibliography.bib]



---


This is my pdf document for milestone 6 of Gov 1006 Final Project. Please refer to the Github repository for my entire project.^[[All analysis for this paper is available on my Github Reposotory](https://github.com/diegomartinez1221/gov_1006_replication)] I am replicating Why Friends and Neighbors? Explaining the Electoral Appeal of Local Roots ^[[Replication Paper](https://www.journals.uchicago.edu/doi/abs/10.1086/703131)] by Rosie Campbell, Philip Cowley, Nick Vivyan, Markus Wagner. They seek to answer how politicians with local roots have greater appeal in elections. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# With the time constrictions due to swithcing papers, I was not able to comment
# all of the replication code. I did comment areas I did need to make changes.

library(bookdown)
library(dplyr)
library(tinytex)
library(gt)
library(gtsummary)
library(stargazer)
library(knitr)
library(tidyverse)
library(devtools)
library(ggplot2)
library(sandwich)
library(lmtest)
library(stargazer)
library(cowplot)
library(cobalt)
library(xtable)
library(devtools)
library(margins)
library(car)
library(foreign)
library(rms)
library(reshape2)
library(plyr)
library(arm)
```


# Mileston 5 

##Paper Overview 

My replication paper will be looking at Rosie Campbell, Philip Cowley, Nick Vivyan, Markus Wagner's paper, "Why Friends and Neighbors? Explaining the Electoral Appeal of Local Roots" published in The Journal of Politics. The paper studies the phenomon of why local politicians seem to gain more electoral support in elections. Whereas the "friends and neigbors" effect has previously been found to arise when there is a lack of information in regard to policy, only thing voters know is they are local, this articles purpose is to explain the "direct effect of local roots on voter evaluations of a politician" [@campbell_cowley_vivyan_wagner_2019]. It is the authors belief that voters "use local roots as a low-cost cue for making inferences about a politician’s “behavioral localism" (an elected official acting in the interest of their [@campbell_cowley_vivyan_wagner_2019]. Their hypothesis is that the power of local roots in decision making for voters is weakened when voters are moer informed about the behavioral localism. The authors use survey experiments of made up candidates running for sets in Parliament in the UK rather than performing an observational study on real elections to isolate the effects of local roots. 

Study 1 used a vignette experiment to more generally test whether the presence of information on behavioral localism impacts the effects of local roots while Study 2 gives people a more wide array of information to test whether having greater knowledge of each candidate elimates the effects of local roots. Study 1 presented a hypothetical election between two candidates and they tested how varying levels of behavioral localism information interacts with being a local candidate. The modeled this with a least squares regression model and their focus was on the interaction term (being a local candidate and having information). The results were that the presence of behavioral information whether positive or negative does lessen the friends and neighbors effect. However, they found being local candidate still positively impacts voters and the authors proceeded to study 2. Since study 2 posseses much more and much more varied information on the candidates in question. They analyze the average marginal component effect (AMCE), the probability of why a candidate is being chosen broken down by each indivual component of their profile (ex. being local, political party, gender). Even here with so much more information, they found the AMCE for being local was positive and one of the most prominent compared to others.

Thus, voters use local roots as an important factor in candidate selection when there is a lack of any other information. However, what is more interesting is that local roots are still a notable factor even when voters have a wider and more in-depth knowledge of each candidate.



## Beautiful Graphic 


```{r, m5 graphic}

# necessary packages. I needed to detach plyr because even though the author
# uses it, it interferes with my use of dplr

detach(package:plyr)
library(tidyverse)
library(dplyr)

# reading in the data for study 1 

d <- readRDS("./friends_neighbors_replication/study1data.rds")

d%>%
  
  # grouping by both treatments variables, creating six groups to find the
  # average score for each candidate. These follows the same groupings used in
  # the article.
  
  group_by(localtreat, behtreat)%>%
  summarise(avg_phil_score = round(mean(philscore), digits = 2),
         avg_nick_score = round(mean(nickscore), digits = 2))%>%
  
  # right now the scores are in two different columns. Pivoting to bring these
  # two together so that I may compare then in a graphic. 
  
  pivot_longer(cols = ends_with("score"), 
               names_to = "candidate",
               values_to = "scores")%>%
  
  # many of the variables names are are currently appreviated or just not in a
  # pretty form for the grap. I use recode to change the variables to better
  # labels in the graph
  
  mutate(candidate = fct_recode(candidate, "Phil" = "avg_phil_score", "Nick" = "avg_nick_score"), 
         behtreat = fct_recode(behtreat, "Constituent focus" = "Const. focus", "National focus" = "Westmin. focus", "No Information" = "No behavioural info"))%>%

  # creating the plot. Chose columns just to be able to see the differences
  # between phil and nick as well as be able to see between the various facets
  
  ggplot() + geom_col(aes(y = scores, x = candidate, fill = candidate), width = 0.5)+
  
  # I use a grid to create a 3x2 graphic for the various treatment combinations. 
  
  facet_grid(behtreat~localtreat) + 
  
  # adding informative labels and titles 
  
  labs(title = "Average Candidate Scores Across Various Treatment Groups",
       subtitle = "Nick Having Local Roots Increases His Average Score Across All Levels of Behavioral\n Localism", x = "Candidate", y = "Scores", caption = "Footnote: Very similar to Figure 1 from `Why Friends and Neighbors? Explaining the Electoral Appeal of Local\n Roots`. I use the raw scores instead of Nick minus Phil for my graphic; however the same results can be seen.\nThe facets of local root vs. not local roots and the behavioral information are all refering to changes to Nick, not Phil,\n and these are the differences in treatment groups") + 
  
  # there is no need for the legend so I take it out to save room. 
  
  theme(legend.position = "none")
```

# Mileston 6 Paper Extensions 

The authors were very thorough in their analysis including a lengthy appendix with a lot of other things that were tested that were not highlighted prominently in the main article. However, I do believe there are a of interesting paths to follow regard to extensions. The authors in their discussion and conclusion provide a lengthy list of questions and extension that arise from their own analysis. However, most of this does involve trying with trying to explain the local roots effect that was out of the scope of their analysis : " What might account for the local roots effects that we have observed but that are left un-explained by the particular mechanisms considered in this article?" [@campbell_cowley_vivyan_wagner_2019]. They go on to speak about theories as well as experiments that should be cared out, including questions and frameworks for experiments with real elections to view how their results play out in an actual race. However, they do not mention much at all about the shortcomings of their analysis (not that there is necessarily any, the analysis was very thorough) and all of these proposed extensions are outside the scope of Gov 1006. My extensions will be focused on the data and experiments they used and will consist of subsetting the data to view how their results apply to various subgroups of the population. 

For study 1, the authors in one of the appendices performed balance and randomization checks to insure that there is a "distributional balance of four respondent characteristics – gender, age, education and social grade, all measured pretreatment – across the six treatment groups created in the experiment" [@campbell_cowley_vivyan_wagner_2019]. Since "None of the differences in proportions across treatment groups are bigger than 10% and only a small number are greater than 5%" [campbell_cowley_vivyan_wagner_2019], I believe this presents an excellent opportunity to dive deeper into if the "friends and neighbors" effect is stronger for one subset of the population than others (ex. males vs. females, older vs. younger). I hypothesis that there may in fact be some interesting differences especially in regard to age. For example, do the younger people in the study, who may not be as engaged in politics or care how they are represented in Parliament, more often vote for the candidate with local roots. Or even on the opposite side of the spectrum, do the elder people in the study who have been engrained in their community and care about their representation vote for the person who will concerned more with the wants and needs of the people than his/her personal political views. I could do a lot more analysis such as this with gender as well and the other personal information included about the people surveyed. 

I am unsure about specific extensions for study 2. Following along the same lines of the extensions I proposed for study 1, I can run a logistic regression model to find the probability a person votes for each type of candidate profile using voter information such as gender, age, education level of the voter themselves. 


# Replication Appendix 

I recreate all the important graphs and tables as specified by Milestone 6. 
```{r, table 1 setup}
# Replication code for Study 1 in 
# Campbell, R., Cowley, P., Vivyan, N & Wagner, M. 
# 'Why friends and neighbors? Explaining the electoral appeal of local roots'.
# Journal of Politics


### Load in Study 1 data

d <- readRDS("./friends_neighbors_replication/study1data.rds")


### Table 2

# The authors created various different models of the data. These models are
# displayed in table 1 of the paper and model 4 is used throughout the paper.
# The authors same the results of the models and the errors in separate objects
# so that they can all be called togethered to create a stargazer table

m1 <- lm(nickminusphil ~ localtreat*behtreatsimple, data = d)

se1 <- sqrt(diag(vcovHC(m1)))

m2 <- lm(nickminusphil ~ localtreat*behtreatsimple +
           gender + agegrp + socgrade + qual
         , data = d)
se2 <- sqrt(diag(vcovHC(m2)))

m3 <- lm(nickminusphil ~ localtreat*behtreat, data = d)
se3 <- sqrt(diag(vcovHC(m3)))

m4 <- lm(nickminusphil ~ localtreat*behtreat +
           gender + agegrp + socgrade + qual
         , data = d)
se4 <- sqrt(diag(vcovHC(m4)))
```

## Table 1
(also fulfills reproducing a table needed for Milestone 5)
```{r table 1, results="asis", message=FALSE, comment=FALSE}
## Output to table

# I needed to change/add many things to the original to get a more similar table
# to the one that apppars in the paper. 

stargazer(header = FALSE, 
          
          # calling all the linear models and errors created in teh previous chunk. 
          
          mget(paste0("m",1:4)),
          se = mget(paste0("se",1:4)),
          
          # latex was the only kind I could get to output in the pdf. It was
          # orignally type html
          
          type = "latex",
          
          # needed to add the title myself as well. 
          
          title = " Relative Ratings of MP Nick by Local Roots and Behavioral Information Treatments in Study", 
          
          # Could not find another way to add the two separations visible in
          # the table model. I needed to use these latex commands combined with
          # column.separate.
          
          column.labels=c('\\shortstack{Conditioning Effect of Any Behavioral\\\\ Localism Information}', '\\shortstack{Separate Conditioning Effects for\\\\ High and Low Behavioral Localism}'),
          column.separate = c(2,2),
          
          # both of these are needed to erase the dependent variable 
          
          dep.var.labels.include = FALSE,
          dep.var.caption = "",
          #intercept.bottom = FALSE, intercept.top = TRUE,
          keep.stat = c("n", "rsq", "adj.rsq"),
          omit = "socgrade|agegrp|gender|qual",
          order = c("Constant", "^localtreatLocal roots$", 
                    "^behtreatsimpleBehavioural info$", 
                    "^behtreatConst. focus$", 
                    "^behtreatWestmin. focus$",
                    "^localtreatLocal roots:behtreatsimpleBehavioural info$",
                    "^localtreatLocal roots:behtreatConst. focus$",
                    "^localtreatLocal roots:behtreatWestmin. focus$"
          ),
          add.lines = list(c("Controls for voter characteristics?", 
                             rep(c("No","Yes"), 2))),
          covariate.labels = c("Intercept", "Local roots", "Behavioral localism information",
                               "Behavioral localism: High (vs. no info)",
                               "Behavioral localism: Low (vs. no info)",
                               "Local roots X Behavioral info.", 
                               "Local roots X High behavioral localism",
                               "Local roots X Low behavioral localism"),
          
          # The notes section was not originally included in the replication
          # code. I was able to create something similar using the latex
          # commends, but it is not an exact match
          
       notes.append = FALSE, notes.align = "l",
      notes.label  = "\\multicolumn{5}{l}{\\parbox[t]{\\textwidth}{Note. All models estimated via ordinary least squares. Dependent variable is respondent relative rating of MP Nick (the 0–10 rating of Nick minus that of Philip). Robust standard errors in parentheses. N p 5,203.}}\\\\"
)

```

##Figure 1

```{r figure 1, cache=TRUE}
### Figure 1

### Create useful functions

## Function to get predicted levels for different treatment combinations.


# function to make predictions from the linear regression on a person with
# different attributes. very much like postior_linpred.the Inputs for the
# function are a regression object, covariate matrix for all the vairables in
# the regression object, and the new data to perform predictions.

predict.rob <- function(object, vcov,newdata){
  
  # extracting info from the regression object
  
  tt <- terms(object)
  
  # check to make sure that the user input a new dataset
  
  if(missing(newdata)){ newdata <- x$model }
  else {
    
    # takes the response variable, the y, out of the terms object
    
    Terms <- delete.response(tt)
    
    # creates a dataframe were all the variables are constant save the local
    # treatment and behavioral treatment. Each row of the matrix is a different
    # combination of the two treatments.
    
    m <- model.frame(Terms, newdata, na.action = na.pass, 
                     xlev = object$xlevels)
    if (!is.null(cl <- attr(Terms, "dataClasses"))) 
      .checkMFClasses(cl, m)
    
    # turns the dataframe m into a dataframe of 1's and 0's for each row of m.
    # This now resembles how m will be fed into a regresson. For example the
    # Intercept is 1 for every row. However, for rows of m where there was an
    # interactions, the value will be 1 and when the interaction did not take
    # place, there will be a 0. Thus, it is a sort of expanded version of the
    # regression equation.
    
    X <- model.matrix(Terms, m, contrasts.arg = object$contrasts)
    
    # checks for if any of the variables are NULL from the original m matrix.
    # this adds in 0's for those instances where there are NULLs.
    
    offset <- rep(0, nrow(X))
    if (!is.null(off.num <- attr(tt, "offset"))) 
      for (i in off.num) offset <- offset + eval(attr(tt, 
                                                      "variables")[[i + 1]], newdata)
    if (!is.null(object$call$offset)) 
      offset <- offset + eval(object$call$offset, newdata)
    mmDone <- FALSE
  }
  #m.mat <- model.matrix(x$terms,data=newdata)
  
  # saving the coefficients from the model 
  
  m.coef <- object$coef
  
  # performing matrix multiplication to get the predicted value for each row,
  # which is each a set person with set attributes experiencing each of the
  # different treatments. Also does the same for the standard erorrs. 
  
  fit <- as.vector(X %*% object$coef)
  se.fit <- sqrt(diag(X%*%vcov%*%t(X)))
  
  # finally the function combines the results of fit and se.fit to lists as the
  # output.
  
  return(list(fit=fit,se.fit=se.fit))
}


## author: Avg treatment effect of local roots with const and westmihn. info

# the margins command will collect the average treatment effect for each of the
# covaraites at every level of behavioral info. This is the crux of the
# analysis. The one that is important to us is the avg effect for
# localtreatLocal roots. Thus subetting to only keep the effects when local
# treatment interacts with the levels of behavioral info.

out <- summary(margins(m4, vcov = vcovHC(m4), 
                       at = list(behtreat = c("No behavioural info", "Const. focus", "Westmin. focus"))))
out <- subset(out, factor == "localtreatLocal roots")
margins.m4 <- out 


## make margins plot
margins.comb <- margins.m4

# changing the variables to be more informative in the graphic. Most were
# abbreviated to save space in the original dataset

margins.comb$behtreat.neat <- car:::recode(margins.comb$behtreat, 
                                           '"No behavioural info" = "Behavioral information treatment --\\nNo information (Vignettes 1-2)";
                                           "Westmin. focus" = "Behavioral information treatment --\\nLow behavioral localism (Vignettes 5-6)";
                                           "Const. focus" = "Behavioral information treatment --\\nHigh behavioral localism (Vignettes 3-4)"')
                                           #as.factor.result = TRUE)
margins.comb$behtreat.neat <- factor(sub(" --", ":", margins.comb$behtreat.neat),
                                     levels = c("Behavioral information treatment:\nNo information (Vignettes 1-2)", 
                                                "Behavioral information treatment:\nLow behavioral localism (Vignettes 5-6)",
                                                "Behavioral information treatment:\nHigh behavioral localism (Vignettes 3-4)"
                                     ))

# the first grahic has two parts that are set side by side. Thus, it is
# necessary to save the plot into an object p1.

p1 <-
  
  # plotting the average treatment effect when a candidate is local for each
  # level of behavioral info; however behavioral info is not yet incorporated
  # into the graph.
  
  ggplot(margins.comb, aes(x = factor, y = AME)) + 
  
  # line at 0 to show all are results are significant
  
  geom_hline(yintercept = 0, linetype = "dashed", size = 0.5) +
  
  # show range of the effect 
  
  geom_linerange(aes(x=factor, ymin=lower, ymax=upper), size = 0.6) +
  
  # point estimate for the averages 
  
  geom_point(size = 3.5, shape = 21, fill = "white") +
  labs(x = "", y = "") + 
  
  # flipping the coordinates because factors is currently all the same. Also
  # aesthetically more pleasing to go horizontally
  
  coord_flip() +
  
  # needing the facet wrap to add the info for each of the behavioral levels.
  # Currently everything was graphed on same axis and the lines were on top of
  # each other. This separates the treatment into each combo of local roots with
  # behavioral roots.
  
  facet_wrap( ~ behtreat.neat, ncol = 1) + 
  
  # manipulating aesthetics and adding a title for the final output.
  
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) + 
  ggtitle("(b) Effect of MP local roots \ntreatment") 

## predlevels for m4

# dataframe created for predictions for the predict.rob function we made
# earlier. The table will consistent of a combinations of all local roots and
# behavioral treatments levels (2,3 so 6 row in total). The table then then is
# filled with the most common value for each of the voter characterstics (most
# common age, gender...). Thus the table is one of the treatments effects on the
# most common of individual from the sample.

newdf <- data.frame(expand.grid(localtreat = factor(c("No local roots", "Local roots"), 
                                                    levels = levels(d$localtreat)),
                                behtreat = factor(levels(d$behtreat), levels = levels(d$behtreat))
),
gender = factor(levels(d$gender)[which.max(table(d$gender))], 
                levels = levels(d$gender)),
agegrp = factor(levels(d$agegrp)[which.max(table(d$agegrp))], 
                levels = levels(d$agegrp)),
socgrade = factor(levels(d$socgrade)[which.max(table(d$socgrade))], 
                  levels = levels(d$socgrade)),
qual = factor(levels(d$qual)[which.max(table(d$qual))], 
              levels = levels(d$qual))
)

# using the function created above to get predictions for each of the rows of
# newdf. The output of pred.rob saved in preds is a list. The next step is
# adding those values into the newdf dataframe to make the second part of
# graphic 1.

preds <- predict.rob(m4, vcov = vcovHC(m4), newdata = newdf)
newdf$yhat <- preds$fit
newdf$se.yhat <- preds$se.fit
newdf$lo <- newdf$yhat - (1.96*newdf$se.yhat)
newdf$hi <- newdf$yhat + (1.96*newdf$se.yhat)
predlevels.m4 <- newdf


## make predlevels plot

# releveling the variables to be more informative in the graphic. Most were
# abbreviated to save space in the original dataset

predlevels.comb <- predlevels.m4
predlevels.comb$behtreat.neat <- car:::recode(predlevels.comb$behtreat, 
                                              '"No behavioural info" = "Behavioral information treatment --\\nNo information (Vignettes 1-2)";
                                              "Westmin. focus" = "Behavioral information treatment --\\nLow behavioral localism (Vignettes 5-6)";
                                              "Const. focus" = "Behavioral information treatment --\\nHigh behavioral localism (Vignettes 3-4)"')
                                              #as.factor.result = TRUE)
predlevels.comb$behtreat.neat <- factor(sub(" --", ":", predlevels.comb$behtreat.neat),
                                        levels = c("Behavioral information treatment:\nNo information (Vignettes 1-2)", 
                                                   "Behavioral information treatment:\nLow behavioral localism (Vignettes 5-6)",
                                                   "Behavioral information treatment:\nHigh behavioral localism (Vignettes 3-4)"
                                        ))
# second plot is pretty much identical to the first plot created. This one is
# just with predicted values for the most common voter profile instead of real
# data.

p2 <- ggplot(predlevels.comb, aes(x = localtreat, y = yhat)) + 
  geom_hline(yintercept = 0, linetype = "dashed", size = 0.5) +
  geom_linerange(aes(x=localtreat, ymin=lo, ymax=hi), size = 0.6) +
  geom_point(size = 3.5, shape = 21, fill = "white") +
  labs(x = "", y = "") + 
  coord_flip() +
  facet_wrap( ~ behtreat.neat, ncol = 1) + 
  theme_bw() +
  theme(legend.position = "bottom") + 
  labs(title = "(a) Predicted relative rating")


## Now combine aspects of above plots into 3 x 2 plot
pcomb <- plot_grid(p2, p1, align = "h", rel_widths = c(1.0,0.80))

```

```{r}
pcomb
```

##Figure 2
```{r figure 2 functions}

    
## Function to get regression-based AMCE estimates for each attribute level using 
## OLS estimator with clustered SEs (Hainmueller, Hopkins and Yammamoto 2014)

# function called within amce.tab to get the actual amce's 

get.amcetab <- function(data, variables, J = 2){    
  
  # important to have the list of variables length to know how many AMCE's to
  # calculate
  
  Nvar <- length(variables)
  amce.list <- vector("list", length = Nvar)
  
  for(i in 1:Nvar){ # get AMCE for each variable attribute
    
    # regression on every variables with mp.preferred individually. fmla builds
    # each regression through each iteration of the loop
    
    fmla <- as.formula(paste("mp.preferred ~ ",variables[i], sep = ""))
    
    # fmla is placed into ols. Runs a linear regression based on the formula.
    # Gets same results for the regression as just calling lm but there are
    # other things in the output as well
    
    model <- ols(fmla, data = data, x = T, y = T) 
    # NOTE: The data for the model has to have no NAs on any model variables 
    # for the robcov(cluster()) function to work 
    
    #adjusts the variance-covariance matrix of a fitto correct for
    #heteroscedasticity and for correlated responses from cluster samples.
    #Clusters by ID, which is each individual person tested as they were tested
    #10 times.
    
    model.clus <- robcov(model, cluster = data$ID, method = "efron")
    
    # list of the coefficients from the model. taking out the baseline because
    # they do comparisons to the baseline
    
    coef <- model.clus$coef[names(model.clus$coef)!="Intercept"]
    
    # calculates as well as gets the standard error for each of the coefficients 
    
    se.clus <- sqrt(diag(model.clus$var))
    se.clus <- se.clus[names(se.clus)!="Intercept"]   
    
    # creating a table from the info drawn from the model 
    
    sub.tab <- data.frame("AMCE" = coef, 
                          "ci.lo" = coef - (1.96*se.clus),
                          "ci.hi" = coef + (1.96*se.clus),
                          "cluster.se" = se.clus)
    
    # making the name of each of the coefficients from the model a column in the
    # created dataframe
    
    sub.tab$category <- names(coef)
    
    # splits into two columns. Since these are categorical variables, the
    # rgression output is the name of the variable being regressed on, and equal
    # sign, and then the category. This separates the variable and the category
    # of the coefficient into two columns
    
    sub.tab <- cbind(sub.tab, colsplit(sub.tab$category, "=", c("attribute","level")))
    sub.tab$level <- as.character(sub.tab$level)    
    
    # no longer needed since made the two columns out of the variable names
    
    row.names(sub.tab) <- NULL
    
    ## add in gaps and baselines
    
    # these had been taken out when we did not want coefficient for the
    # intercept. Now it is added back into table for reference as 0's
    
    to.add <- data.frame(AMCE = c(NA,NA, 0), ci.lo = c(NA,NA, 0), ci.hi = c(NA,NA, 0),
                         cluster.se = c(NA,NA, 0),
                         category = rep("", 3), attribute = rep(sub.tab$attribute[1],3),
                         level = c("", " ", "baseline"))
    
    # since this is a for loop will do the same for each regression
    # individually. All are saved into amce.list
    
    amce.list [[i]] <- rbind(to.add, sub.tab)
  } 
  
  # create one large table from the list of individual subtables for each regression 
  
  amce.tab <- do.call("rbind", amce.list)
  
  # re-make initial labels column
  
  amce.tab$category <- paste(amce.tab$attribute, amce.tab$level, sep = ": ")
  
  # make this into ordered factor
  amce.tab$category <- factor(amce.tab$category, levels = rev(amce.tab$category), order =T)    
  
  return(amce.tab)
}


## author: Function that calls get.amcetab for multiple predictors and combines results

# inputs for the function are a dataframe, variables from dataframe wanting to
# be used to get their amce and whether there are multiple datasets, and if they
# test subjects are in same political party.

# amce.tab only function is to prepare data so as to call get_amcetab. That is
# why there are many if statements for different number of datasets and parties.

amce.tab <- function(data, variables, multi = F, same.party = F){
  # data must be a single data frame or a list of data frames (if multi = T)
  # with named elements
  # Also relies on specific ordering of explanatory variables

  # first try when multi is true. What is going on here is iterating over the
  # list of dataframes all calling get_amcetab for each of the dataframes in the
  # list. Necessary that all dataframes have the variables inputed into the
  # orignal function
  
  if(multi == T & same.party == F){
    amce.tab.list <- list(NA, length = length(data))
    for(i in 1:length(data)){
      tmp <- get.amcetab(data[[i]], variables = variables)
      tmp$set <- rep(names(data)[i], nrow(tmp))
      amce.tab.list[[i]] <- tmp
    }
    
    # combining all the dataframes together to create one large dataset with set
    # column to be able to tell which amce belongs to which dataset from the list.
    
    amce.tab <- do.call("rbind",amce.tab.list)
    amce.tab$set <- factor(amce.tab$set)
    return(amce.tab)
  }
  

  # same as before in needing to iterate over every dataset in the list of
  # datasets and call get_amcetab for all of them
  
  if(multi == T & same.party == T){
    amce.tab.list <- list(NA, length = length(data))
    for(i in 1:length(data)){
      
      # check for same party. If they are the same party. If true, the first
      # variable is taken out of the variable list. This is why author stated
      # that the order of variables is important.
      
      vars <- if(grepl("same party", names(data)[i])==T|grepl("Same Party", names(data)[i])==T) variables[2:length(variables)] else variables
      
      # regardless now calls get.amcetab for every element of the list
      
      tmp <- get.amcetab(data[[i]], variables = vars)
      tmp$set <- rep(names(data)[i], nrow(tmp))
      amce.tab.list[[i]] <- tmp
    }
    names(amce.tab.list) <- names(data)
    
    # separtes the data where they are same party and datasets where they
    # are not in same party
    diff.party <- amce.tab.list[grepl("same party", names(amce.tab.list))==F&
                                  grepl("Same Party", names(amce.tab.list))==F]
    same.party <- amce.tab.list[grepl("same party", names(amce.tab.list))==T |
                                  grepl("Same Party", names(amce.tab.list))==T]
    
    # dataframe to fill in when they are same party 
    
    to.add <- data.frame(AMCE = rep(NA, 4), ci.lo = rep(NA, 4), ci.hi =  rep(NA, 4),
                         cluster.se =  rep(NA, 4),
                         category =  diff.party[[1]]$category[1:4], 
                         attribute =  diff.party[[1]]$attribute[1:4], 
                         level = diff.party[[1]]$level[1:4],
                         set = rep(NA, 4))
    
    for(i in 1:length(data)){ 
      
      #replacing results from amcetab when same party is true.  
      
      if(grepl("same party", names(data)[i])==T|grepl("Same Party", names(data)[i])==T){
        amce.tab.list[[i]] <- rbind(to.add,amce.tab.list[[i]])
        amce.tab.list[[i]]$set[1:4] <-  amce.tab.list[[i]]$set[5:8]
      }
      else amce.tab.list[[i]] <- amce.tab.list[[i]]
    }    
    
    # finally combines all the datasets from the list of datasets together and
    # outputs the results together.
    
    amce.tab <- do.call("rbind",amce.tab.list)
    amce.tab$set <- factor(amce.tab$set)
    return(amce.tab)
  } 
  
  # last if statement and it is the easiest just when multi is false. All
  # amce.tab needs does is just call get.amcetab
  
  if(multi == F)   {
    
    get.amcetab(data, variables)
  }
  
}


```


```{r figure 2 graph, message=FALSE, warning=FALSE}
### Load in Study 2 data 

long.dat <- readRDS("./friends_neighbors_replication/study2data_long.rds")
wide.dat <- readRDS("./friends_neighbors_replication/study2data_wide.rds")


### Create labels for plotting

# for full results

# more informative labels 

labels.full <- rev(expression(
  "", italic("Party & position (baseline = Labour left-wing)"), "Labour centre", "Conservative centre", "Conservative right-wing",
  "", italic("Local roots (baseline = lives elsewhere)"),"5 years in area", "20 years in area", "Grew up and lives in area", 
  "", italic("Constituency work (baseline = 1 day)"), "2 days", "3 days", "4 days",
  "", italic("Main policy influence (baseline = party)"), "constituents' views","own personal views",
  "", italic("Policy interests (baseline = economy and tax)"), "education and health",
  "", italic("MP sex (baseline = female)"), "male"))

# for analysis of local roots only
labels.sub <- expression("Grew up and lives in area", "20 years in area", "5 years in area", 
                         italic("Local roots (baseline = lives elsewhere)"))


# label for x axis

effect.label <- "Change in probability of MP being preferred,\n relative to baseline"


### Figure 3: AMCEs for all attributes

# calling amce.tab to get the amce values for all these variables when used as
# explanatory variable for mp.preferred

res <- amce.tab(data = long.dat, 
                variables = c("mp.partypos", "mp.localroots", "mp.const", "mp.influence", "mp.policy", "mp.gender")
                , multi = F)

# reversing the order of the factors for the various categories of amce, unsure
# why

res$category <- factor(as.character(res$category), levels = rev(as.character(res$category)), order =T)
#write.csv(res, "amce-all.csv")# write results to csv file

# Full plot for all attributes

# since each had two spaces in between, the top one is not needed.

res <- res[2:nrow(res),] # chop off top empty layer
res <- subset(res, level != "baseline")# remove artificial 'baseline' rows

# labels created above

labels <- labels.full

# initiates the plot. The attribute column is each variable which is why every
# category within a variable has same color.

ggplot(res, aes(x = category, y = AMCE, color = attribute)) + 
  
  # baseline of 0 to show how significant each coefficient is 
  
  geom_hline(yintercept = 0, linetype = "dashed", size = 0.5) +
  
  # gives the standard error range and a point at the amce
  
  geom_pointrange(aes(ymin = ci.lo, ymax = ci.hi), size = 0.75) +
  
  # inputs better label for y axis (Will become x axis)
  labs(y = effect.label, x = "") + 
  
  # With the categories on x axis, everything is jumbled, thus flipping the
  # coordinates so the categories are legible
  
  coord_flip() + 
  
  # adding nice formating 
  
  theme_bw() + 
  theme(axis.text = element_text(colour = "black")) +
  theme(legend.position = "none") +
  theme(text = element_text(size = 15)) +
  theme(axis.ticks.y = element_blank(), axis.text.y = element_text(hjust = 1), # remove ticks and justify
        axis.title.x = element_text(size = 13, vjust = 0)) + 
  
  # change labels from those from the dataset that were abbreivated to something
  # more infomrative
  
  scale_x_discrete(labels=labels)

```

## Replication: What I Achieved and What I Did Not 

I was able to replicate all the code of the paper. There were some errors based on updating of packages. I had the most difficulty with trying to replicate the stargazer table. The code by itself did not have the note at the bottom nor the column headers. I was not able to replicate the table exaclty, however, I was ablle to figure out how to make it as similar as possible. I did so manipulating the Latex of the stargazer output. 

# Citations 

The data and code for this replication is from Dataverse [@campbell_cowley_vivyan_wagner_2018]. I used the stargazer package to replicate tables [@stargazer] and I follow reccomendations made by Gary King for replication [@king]. I use many techniques from the Gov 1006 textbook "Regression and Other Stories" [@RAOS] as well.

#Bibliography